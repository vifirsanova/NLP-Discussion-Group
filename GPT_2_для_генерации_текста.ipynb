{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT-2 для генерации текста",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3avOzKc2NpRQ",
        "colab_type": "text"
      },
      "source": [
        "*Материал оформила и подготовила* Виктория Фирсанова"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_",
        "colab_type": "text"
      },
      "source": [
        "#  **Тонкая настройка GPT-2 для генерации текста**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "c280c8e0-b151-4e80-82f6-ff06e1bd4aa9"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS",
        "colab_type": "text"
      },
      "source": [
        "## Доступные модели\n",
        "\n",
        "Размер модели зависит от количества параметров (а количество настроек - от количества слоев). Для обучения использовалось 8 миллионов сайтов, 40 Гб текста. \n",
        "\n",
        "|Параметры | Слои | Соответствие |\n",
        "| ---------| ---- |------------|\n",
        "117M | 12 | Предшествующая GPT\n",
        "345M | 24 | Самая большая модель BERT\n",
        "762M | 36 | \n",
        "1542M | 48 | GPT-2\n",
        "\n",
        "Варианты GPT-2, доступные для использования (отличаются от перечисленных в оригинальной статье):\n",
        "\n",
        "*   117M\n",
        "*   124M\n",
        "*   355M\n",
        "*   774M\n",
        "*   1558M\n",
        "\n",
        "Чем больше модель, тем больше времени вам потребуется на ее настройку (логично), но и качество генерации текста будет заметно выше.\n",
        "\n",
        "Почему в таком случае сразу не перейти к GPT-3? Что ж, доступ к ней не так легко получить. Но вы можете попробовать: https://beta.openai.com/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3",
        "colab_type": "text"
      },
      "source": [
        "## **Файн-тюнинг модели**\n",
        "\n",
        "Сессия TensorFlow, в которой обучение проводится заданное количество шагов (можно задать бесконечное обучение `steps = -1`).\n",
        "\n",
        "Параметры:\n",
        "\n",
        "*  **`restore_from`**: запускаем `fresh`, чтобы начать обучение с базовой GPT-2, или `latest`, чтобы перезапустить обучение с контрольной точки.\n",
        "* **`sample_every`**: количество шагов, спустя которое будет выведен пример работы модели на данном этапе обучения.\n",
        "* **`print_every`**: количество шагов, спустя которого выводится прогресс обучения.\n",
        "*  **`run_name`**: подпапка `checkpoint`, используется для сохранения модели. Полезно, если вы работаете с несколькими моделями. \n",
        "* **`overwrite`**: позволяет продолжать настройку существующей модели, не создавая дубликатов. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=5000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQAN3M6RT7Kj",
        "colab_type": "text"
      },
      "source": [
        "## **Запуск предобученной модели**\n",
        "\n",
        "*  **`length`**: количество токенов для генерации (по умолчанию = 1023).\n",
        "* **`temperature`**: чем выше этот параметр, тем безумнее получится текст (по умолчанию = 0.7).\n",
        "* **`top_k`**: ограничивает сгенерированные предсказания до верхних *k* (0 отключает эту опцию - по умолчанию) - еще одно средство для обеспечения адекватности.\n",
        "* **`top_p`**: обеспечивает кумулятивное распрделение предсказаний (рекомендованный размер = 0.9).\n",
        "* **`truncate`**: обрезает инпут до заданного ограничения, функция полезна при работе с низкими значениями `length`.\n",
        "*  **`include_prefix`**: дополнение к `truncate`, обозначенный `prefix` будет включен в вывод."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsUd_jHgUZnD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "eade0e2a-583a-47c2-e962-6effe86048d0"
      },
      "source": [
        "model_name = \"774M\"\n",
        "\n",
        "gpt2.download_gpt2(model_name=model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 258Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 128Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 393Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 3.10Git [00:49, 62.6Mit/s]                                 \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 474Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 2.10Mit [00:00, 142Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 117Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAe4NpKNUj2C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9fb2e29c-2d51-434a-b56c-6079514fe2eb"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.load_gpt2(sess, model_name=model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading pretrained model models/774M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/774M/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xInIZKaU104",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "outputId": "2ca01fe8-94d5-4697-8fe9-20ad6099bf56"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              model_name=model_name,\n",
        "              prefix=\" Hi! \",\n",
        "              length=100,\n",
        "              temperature=1,\n",
        "              top_p=0.9,\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:32: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            " Hi!  In II, I take one step back and examine our collective project and how it relates to our present.  Before discussing this case, it's useful to remind ourselves what I think of as our  OUPposture that fosters systematic self-deception.  If you read it through, you'll see that the surface of the articulation is a fixation on food (that we obtain, cook, and eat) and exercise, but that at the core of the post\n",
            "====================\n",
            " Hi! ~~~~~ O:O ~~~~~ D:O O:O In D:O I always cry... I always go abroad... I hope it's too late I think my fate is to be married in future to girls... Because this day I live by fear of not knowing... For getting down on myself, it's like I refuse to look at things and pursue them, it's like I won't take them into my hands... __________________________________________________________________________________________________________________________________________________________ When I opened the door, the\n",
            "====================\n",
            " Hi! 」\n",
            "\n",
            "「…The boy is about 15 years old」\n",
            "\n",
            "I leave the room, and return back to the school…\n",
            "\n",
            "Then, on the morning of the second day, I call the Teacher…\n",
            "\n",
            "「Zanma-san, do you know a girl named 『Chloe』?」\n",
            "\n",
            "…Eh?\n",
            "\n",
            "「Zanma-san is the only girl who knows 『Chloe』」\n",
            "\n",
            "「Then…You should go to the\n",
            "====================\n",
            " Hi! ------------ ANCIENT WORLD OF MAGIC, A GAME ABOUT ALIEN INVASION OF THIS PLANET By Patrick Rothfuss If anyone has any questions about the book they can also send me an email or reach out to me on Facebook, Twitter, or Reddit, but please be understanding that it is my job to be a general guide and I can't answer everything. ------------ *U.S.A. *Fantasy books are terrible to read. For all the criticism it receives\n",
            "====================\n",
            " Hi!  I've got a review of our video here  and a review of the May collection here . More on all of the May collection from Ama has dropped:\n",
            "Up Next: More Spring/Summer Collections<|endoftext|>Copyright (c) Queen's Printer,\n",
            "\n",
            "Victoria, British Columbia, Canada License\n",
            "\n",
            "Disclaimer\n",
            "\n",
            "B.C. Reg. 312/96, s. 1\n",
            "\n",
            "Definitions\n",
            "\n",
            "3 In this Act,\n",
            "\n",
            "\"acquisition\" means any transaction\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRKQG65qPfxO",
        "colab_type": "text"
      },
      "source": [
        "**Список источников:**\n",
        "\n",
        "1. Radford, A., Wu, J., Child, R., Luan, D., Amodei, D. & Sutskever, I. (2019). Language Models are Unsupervised Multitask Learners. Technical report, OpenAI\n",
        "2. Woolf, M. How To Make Custom AI-Generated Text With GPT-2. (2019). Max Woolf's Blog. URL: https://minimaxir.com/2019/09/howto-gpt2/ "
      ]
    }
  ]
}